{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163817"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\ufeffproject gutenberg’s alice’s adventures in wonderland, by lewis carroll\\n\\nthis ebook is for the use o'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('Text/AliceInWonderLand.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "len(text)\n",
    "type(text)\n",
    "text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can get Text directly also as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163817"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\ufeffproject gutenberg’s alice’s adventures in wonderland, by lewis carroll\\n\\nthis ebook is for the use o'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = open('Text/AliceInWonderLand.txt', encoding='utf-8').read().lower()\n",
    "len(text)\n",
    "type(text)\n",
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_percent_change(raw_text, mod_text):\n",
    "    import numpy as np\n",
    "    \n",
    "    pct_change = ((len(raw_text) - len(mod_text)) / len(raw_text))*100\n",
    "    return print('Percent Change is: ', np.round(pct_change, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data Help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Stopwords + Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "len(stop)\n",
    "len(punctuation)\n",
    "\n",
    "_stopwords = stop + list(punctuation)\n",
    "len(_stopwords)\n",
    "_stopwords[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111242"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Change is:  32.09\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ufeffproject gutenberg’s alice’s adventures wonderland, lewis carroll ebook use anyone anywhere cost alm'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text = ' '.join(_text for _text in text.split() if _text not in _stopwords)\n",
    "len(clean_text)\n",
    "fun_percent_change(text, clean_text)\n",
    "clean_text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basis NLTK's WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106691"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Change is:  4.09\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ufeffproject gutenberg’s alice’s adventure wonderland, lewis carroll ebook use anyone anywhere cost almo'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text_lem_nltk = ''\n",
    "clean_text_lem_nltk = ' '.join(lem.lemmatize(_text, pos='v') for _text in clean_text.split())\n",
    "len(clean_text_lem_nltk)\n",
    "fun_percent_change(clean_text, clean_text_lem_nltk)\n",
    "clean_text_lem_nltk[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basis 'textblob's' Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110584"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Change is:  0.59\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ufeffproject gutenberg’s alice’s adventure wonderland, lewis carroll ebook use anyone anywhere cost almo'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text_lem_blob = ''\n",
    "clean_text_lem_blob = ' '.join(Word(_text).lemmatize() for _text in clean_text.split())\n",
    "len(clean_text_lem_blob)\n",
    "fun_percent_change(clean_text, clean_text_lem_blob)\n",
    "clean_text_lem_blob[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Unwanted Characters Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106126"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'project gutenberg’s alice’s adventure wonderland, lewis carroll ebook use anyone anywhere cost almos'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_remove = ['\\ufeff','\\n','`','~','@','#','%','^','*','--']\n",
    "clean_text_char_rem = ''\n",
    "for i,char in enumerate(to_remove):\n",
    "    if i == 0:\n",
    "        clean_text_char_rem = clean_text_lem_nltk.replace(char, '')\n",
    "    else:\n",
    "        clean_text_char_rem = clean_text_char_rem.replace(char, '')\n",
    "len(clean_text_char_rem)\n",
    "clean_text_char_rem[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Change is:  0.53\n",
      "Percent Change is:  4.6\n",
      "Percent Change is:  35.22\n"
     ]
    }
   ],
   "source": [
    "fun_percent_change(clean_text_lem_nltk, clean_text_char_rem)\n",
    "fun_percent_change(clean_text, clean_text_char_rem)\n",
    "fun_percent_change(text, clean_text_char_rem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Common Word Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['project',\n",
       " 'gutenberg’s',\n",
       " 'alice’s',\n",
       " 'adventure',\n",
       " 'wonderland,',\n",
       " 'lewis',\n",
       " 'carroll',\n",
       " 'ebook',\n",
       " 'use',\n",
       " 'anyone']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text_char_rem.split()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4929"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "say        471\n",
       "alice      221\n",
       "go         160\n",
       "‘i         122\n",
       "little     120\n",
       "think      111\n",
       "get        109\n",
       "look       100\n",
       "project     82\n",
       "one         81\n",
       "make        78\n",
       "like        78\n",
       "alice,      76\n",
       "would       76\n",
       "begin       76\n",
       "come        70\n",
       "could       66\n",
       "see         64\n",
       "know        64\n",
       "work        62\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "common_word_freq = pd.Series(clean_text_char_rem.split()).value_counts()\n",
    "len(common_word_freq)\n",
    "common_word_freq[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "471"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Index(['say', 'alice', 'go', '‘i', 'little', 'think', 'get', 'look', 'project',\n",
       "       'one', 'make', 'like', 'alice,', 'would', 'begin', 'come', 'could',\n",
       "       'see', 'know', 'work'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "94784"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Change is:  42.14\n"
     ]
    }
   ],
   "source": [
    "common_word_freq[0]\n",
    "common_word_freq[2]\n",
    "# Checking for 1st 20 words to be removed\n",
    "common_word_freq.index[:20]\n",
    "clean_text_post_commonWord_removal = ''\n",
    "clean_text_post_commonWord_removal = ' '.join(_char for _char in clean_text_char_rem.split() \n",
    "                                              if _char not in common_word_freq.index[:20])\n",
    "len(clean_text_post_commonWord_removal)\n",
    "fun_percent_change(text, clean_text_post_commonWord_removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gutenberg’s alice’s adventure wonderland, lewis carroll ebook use anyone anywhere cost almost restri'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text_post_commonWord_removal[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Rare Word Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4909"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "fact.        1\n",
       "boldly:      1\n",
       "bat          1\n",
       "altered.’    1\n",
       "honour,      1\n",
       "pop          1\n",
       "five.        1\n",
       "hookah,      1\n",
       "‘with        1\n",
       "way!         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rare_word_freq = pd.Series(clean_text_post_commonWord_removal.split()).value_counts()\n",
    "len(rare_word_freq)\n",
    "rare_word_freq[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['were’,', 'tea-time.', '[‘the', 'us!”’', '‘herald,', 'gross', 'sugar',\n",
       "       'caper', 'stick', 'inaccurate', 'fact.', 'boldly:', 'bat', 'altered.’',\n",
       "       'honour,', 'pop', 'five.', 'hookah,', '‘with', 'way!'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rare_word_freq.index[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94646"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Change is:  42.22\n"
     ]
    }
   ],
   "source": [
    "clean_text_post_rareWord_removal = ''\n",
    "clean_text_post_rareWord_removal = ' '.join(_char for _char in clean_text_post_commonWord_removal.split() \n",
    "                                            if _char not in rare_word_freq.index[-20:])\n",
    "len(clean_text_post_rareWord_removal)\n",
    "fun_percent_change(text, clean_text_post_rareWord_removal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting all this in a single function which can be called externally in any program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_get_data():\n",
    "    # Get Data\n",
    "    print('<< 1. Reading Data >>')\n",
    "    with open('Text/AliceInWonderLand.txt', 'r', encoding='utf-8') as f:\n",
    "        text = f.read().lower()\n",
    "    print('Actual Length of Text : ', len(text))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_clean_stopwords_punct(original_text):\n",
    "    print('*'*50)\n",
    "    print('<< 2. Applying StopWords and Punctuation removal >>')\n",
    "    \n",
    "    from nltk.corpus import stopwords\n",
    "    from string import punctuation\n",
    "    \n",
    "    stop = stopwords.words('english')\n",
    "    _stopwords = set(stop + list(punctuation))\n",
    "    clean_text = ' '.join(_text for _text in original_text.split() if _text not in _stopwords)\n",
    "    \n",
    "    print('Length post removing stopwords and punctuation : ',len(clean_text))\n",
    "    print(fun_percent_change(original_text, clean_text))\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_clean_lemmatization(passedText, original_text):\n",
    "    print('*'*50)\n",
    "    print('<< 3. Applying Lemmatization >>')\n",
    "    \n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    \n",
    "    lem = WordNetLemmatizer()\n",
    "    clean_text = ' '.join(lem.lemmatize(_text, pos='v') for _text in passedText.split())\n",
    "    \n",
    "    print('Length of text post applying Lemmatization : ', len(clean_text))\n",
    "    print(fun_percent_change(original_text, clean_text))\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_clean_removing_unwantedWords(passedText, original_text):\n",
    "    print('*'*50)\n",
    "    print('<< 4. Applying Removal of Unwanted Characters >>')\n",
    "    \n",
    "    to_remove = ['\\ufeff','\\n','`','~','@','#','%','^','*','--']\n",
    "    clean_text_char_rem = ''\n",
    "    \n",
    "    for i,char in enumerate(to_remove):\n",
    "        if i == 0:\n",
    "            clean_text = passedText.replace(char, '')\n",
    "        else:\n",
    "            clean_text = clean_text.replace(char, '')\n",
    "    \n",
    "    print('Length of text post removal of Unwanted Characters : ', len(clean_text))\n",
    "    print(fun_percent_change(original_text, clean_text))\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_clean_removing_commonWords(passedText, original_text):\n",
    "    print('*'*50)\n",
    "    print('<< 5. Applying Removal of Common or Frequently Occuring Words >>')\n",
    "    \n",
    "    import pandas as pd\n",
    "    \n",
    "    common_word_freq = pd.Series(passedText.split()).value_counts()[:20] # taking only 1st 20 words\n",
    "    \n",
    "    clean_text = ' '.join(_char for _char in passedText.split() if _char not in common_word_freq.index)\n",
    "    print('Length of text post removal of Common Words : ', len(clean_text))\n",
    "    print(fun_percent_change(original_text, clean_text))\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_clean_removing_rareWords(passedText, original_text):\n",
    "    print('*'*50)\n",
    "    print('<< 6. Applying Removal of Rare Occuring Words >>')\n",
    "    \n",
    "    import pandas as pd\n",
    "    \n",
    "    common_word_freq = pd.Series(passedText.split()).value_counts()[-20:] # taking only last 20 words\n",
    "    \n",
    "    clean_text = ' '.join(_char for _char in passedText.split() if _char not in common_word_freq.index)\n",
    "    print('Length of text post removal of Rare Orccuring Words : ', len(clean_text))\n",
    "    print(fun_percent_change(original_text, clean_text))\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_clean_text():    \n",
    "    # Get Data\n",
    "    original_text = fun_get_data()\n",
    "    \n",
    "    # Clean Data\n",
    "    # 1: Remove Stop Words and Puctuation\n",
    "    clean_text = fun_clean_stopwords_punct(original_text)\n",
    "    \n",
    "    # 2: Lemmatization\n",
    "    clean_text_lem_nltk = fun_clean_lemmatization(clean_text, original_text)\n",
    "    \n",
    "    # 3. Removing unwanted text\n",
    "    clean_text_char_rem = fun_clean_removing_unwantedWords(clean_text_lem_nltk, original_text)\n",
    "    \n",
    "    # 4. Removing Common Words\n",
    "    clean_text_post_commonWord_removal = fun_clean_removing_commonWords(clean_text_char_rem, original_text)\n",
    "    \n",
    "    # 5. Removing Rare Occuring Words\n",
    "    clean_text_post_rareWord_removal = fun_clean_removing_rareWords(clean_text_post_commonWord_removal, original_text)\n",
    "    \n",
    "    return clean_text_post_rareWord_removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<< 1. Reading Data >>\n",
      "Actual Length of Text :  163817\n",
      "**************************************************\n",
      "<< 2. Applying StopWords and Punctuation removal >>\n",
      "Length post removing stopwords and punctuation :  111242\n",
      "Percent Change is:  32.09\n",
      "None\n",
      "**************************************************\n",
      "<< 3. Applying Lemmatization >>\n",
      "Length of text post applying Lemmatization :  106691\n",
      "Percent Change is:  34.87\n",
      "None\n",
      "**************************************************\n",
      "<< 4. Applying Removal of Unwanted Characters >>\n",
      "Length of text post removal of Unwanted Characters :  106126\n",
      "Percent Change is:  35.22\n",
      "None\n",
      "**************************************************\n",
      "<< 5. Applying Removal of Common or Frequently Occuring Words >>\n",
      "Length of text post removal of Common Words :  94784\n",
      "Percent Change is:  42.14\n",
      "None\n",
      "**************************************************\n",
      "<< 6. Applying Removal of Rare Occuring Words >>\n",
      "Length of text post removal of Rare Orccuring Words :  94646\n",
      "Percent Change is:  42.22\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "clean_text = fun_clean_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
